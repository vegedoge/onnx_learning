{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "model.eval()\n",
    "\n",
    "# summary(model, input_size=(1, 3, 224, 224))\n",
    "\n",
    "# 打印模型的输入输出\n",
    "\n",
    "\n",
    "# 使用trace实现ir需要一个dummy_input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# ir\n",
    "with torch.no_grad():\n",
    "    jit_model = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.11 : __torch__.torch.nn.modules.container.___torch_mangle_415.Sequential,\n",
      "      %4 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu)):\n",
      "  %_1.1 : __torch__.torchvision.models.resnet.___torch_mangle_414.BasicBlock = prim::GetAttr[name=\"1\"](%self.11)\n",
      "  %_0.1 : __torch__.torchvision.models.resnet.___torch_mangle_408.BasicBlock = prim::GetAttr[name=\"0\"](%self.11)\n",
      "  %6 : Tensor = prim::CallMethod[name=\"forward\"](%_0.1, %4)\n",
      "  %7 : Tensor = prim::CallMethod[name=\"forward\"](%_1.1, %6)\n",
      "  return (%7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jit_layer1 = jit_model.layer1\n",
    "print(jit_layer1.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  _1 = getattr(self, \"1\")\n",
      "  _0 = getattr(self, \"0\")\n",
      "  _2 = (_1).forward((_0).forward(argument_1, ), )\n",
      "  return _2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jit_layer1.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.11 : __torch__.torch.nn.modules.container.___torch_mangle_415.Sequential,\n",
      "      %4 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu)):\n",
      "  %_1.1 : __torch__.torchvision.models.resnet.___torch_mangle_414.BasicBlock = prim::GetAttr[name=\"1\"](%self.11)\n",
      "  %_0.1 : __torch__.torchvision.models.resnet.___torch_mangle_408.BasicBlock = prim::GetAttr[name=\"0\"](%self.11)\n",
      "  %8 : float = prim::Constant[value=0.10000000000000001](), scope: __module.layer1/__module.layer1.0/__module.layer1.0.bn1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.layer1/__module.layer1.0/__module.layer1.0.bn1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %10 : NoneType = prim::Constant(), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1\n",
      "  %11 : int = prim::Constant[value=1](), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %12 : bool = prim::Constant[value=0](), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %13 : int = prim::Constant[value=0](), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %14 : bool = prim::Constant[value=1](), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %bn2.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_407.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.1)\n",
      "  %conv2.1 : __torch__.torch.nn.modules.conv.___torch_mangle_406.Conv2d = prim::GetAttr[name=\"conv2\"](%_0.1)\n",
      "  %relu.3 : __torch__.torch.nn.modules.activation.___torch_mangle_405.ReLU = prim::GetAttr[name=\"relu\"](%_0.1)\n",
      "  %bn1.3 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_404.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.1)\n",
      "  %conv1.3 : __torch__.torch.nn.modules.conv.___torch_mangle_403.Conv2d = prim::GetAttr[name=\"conv1\"](%_0.1)\n",
      "  %weight.85 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.3)\n",
      "  %21 : int[] = prim::ListConstruct(%11, %11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1\n",
      "  %22 : int[] = prim::ListConstruct(%11, %11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1\n",
      "  %23 : int[] = prim::ListConstruct(%11, %11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1\n",
      "  %24 : int[] = prim::ListConstruct(%13, %13), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1\n",
      "  %input.9 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::_convolution(%4, %weight.85, %10, %21, %22, %23, %12, %24, %11, %12, %12, %14, %14), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %running_var.43 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.3)\n",
      "  %running_mean.43 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.3)\n",
      "  %bias.43 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.3)\n",
      "  %weight.87 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.3)\n",
      "  %input.11 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.9, %weight.87, %bias.43, %running_mean.43, %running_var.43, %12, %8, %9, %14), scope: __module.layer1/__module.layer1.0/__module.layer1.0.bn1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %input.13 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::relu_(%input.11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.relu # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:1498:0\n",
      "  %weight.89 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.1)\n",
      "  %33 : int[] = prim::ListConstruct(%11, %11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv2\n",
      "  %34 : int[] = prim::ListConstruct(%11, %11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv2\n",
      "  %35 : int[] = prim::ListConstruct(%11, %11), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv2\n",
      "  %36 : int[] = prim::ListConstruct(%13, %13), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv2\n",
      "  %input.15 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.13, %weight.89, %10, %33, %34, %35, %12, %36, %11, %12, %12, %14, %14), scope: __module.layer1/__module.layer1.0/__module.layer1.0.conv2 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %running_var.45 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.1)\n",
      "  %running_mean.45 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.1)\n",
      "  %bias.45 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.1)\n",
      "  %weight.91 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.1)\n",
      "  %out.1 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.15, %weight.91, %bias.45, %running_mean.45, %running_var.45, %12, %8, %9, %14), scope: __module.layer1/__module.layer1.0/__module.layer1.0.bn2 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %input.17 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::add_(%out.1, %4, %11), scope: __module.layer1/__module.layer1.0 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %input.19 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::relu_(%input.17), scope: __module.layer1/__module.layer1.0/__module.layer1.0.relu # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:1498:0\n",
      "  %45 : float = prim::Constant[value=0.10000000000000001](), scope: __module.layer1/__module.layer1.1/__module.layer1.1.bn1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %46 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.layer1/__module.layer1.1/__module.layer1.1.bn1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %47 : NoneType = prim::Constant(), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1\n",
      "  %48 : int = prim::Constant[value=1](), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %49 : bool = prim::Constant[value=0](), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %50 : int = prim::Constant[value=0](), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %51 : bool = prim::Constant[value=1](), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %bn2.3 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_413.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.1)\n",
      "  %conv2.3 : __torch__.torch.nn.modules.conv.___torch_mangle_412.Conv2d = prim::GetAttr[name=\"conv2\"](%_1.1)\n",
      "  %relu.5 : __torch__.torch.nn.modules.activation.___torch_mangle_411.ReLU = prim::GetAttr[name=\"relu\"](%_1.1)\n",
      "  %bn1.5 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_410.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.1)\n",
      "  %conv1.5 : __torch__.torch.nn.modules.conv.___torch_mangle_409.Conv2d = prim::GetAttr[name=\"conv1\"](%_1.1)\n",
      "  %weight.93 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.5)\n",
      "  %58 : int[] = prim::ListConstruct(%48, %48), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1\n",
      "  %59 : int[] = prim::ListConstruct(%48, %48), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1\n",
      "  %60 : int[] = prim::ListConstruct(%48, %48), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1\n",
      "  %61 : int[] = prim::ListConstruct(%50, %50), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1\n",
      "  %input.21 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.19, %weight.93, %47, %58, %59, %60, %49, %61, %48, %49, %49, %51, %51), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %running_var.47 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.5)\n",
      "  %running_mean.47 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.5)\n",
      "  %bias.47 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.5)\n",
      "  %weight.95 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.5)\n",
      "  %input.23 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.21, %weight.95, %bias.47, %running_mean.47, %running_var.47, %49, %45, %46, %51), scope: __module.layer1/__module.layer1.1/__module.layer1.1.bn1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %input.25 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::relu_(%input.23), scope: __module.layer1/__module.layer1.1/__module.layer1.1.relu # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:1498:0\n",
      "  %weight.97 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.3)\n",
      "  %70 : int[] = prim::ListConstruct(%48, %48), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv2\n",
      "  %71 : int[] = prim::ListConstruct(%48, %48), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv2\n",
      "  %72 : int[] = prim::ListConstruct(%48, %48), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv2\n",
      "  %73 : int[] = prim::ListConstruct(%50, %50), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv2\n",
      "  %input.27 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.25, %weight.97, %47, %70, %71, %72, %49, %73, %48, %49, %49, %51, %51), scope: __module.layer1/__module.layer1.1/__module.layer1.1.conv2 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %running_var.49 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.3)\n",
      "  %running_mean.49 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.3)\n",
      "  %bias.49 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.3)\n",
      "  %weight.99 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.3)\n",
      "  %out.3 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.27, %weight.99, %bias.49, %running_mean.49, %running_var.49, %49, %45, %46, %51), scope: __module.layer1/__module.layer1.1/__module.layer1.1.bn2 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:2512:0\n",
      "  %input.29 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::add_(%out.3, %input.19, %48), scope: __module.layer1/__module.layer1.1 # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %input.31 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = aten::relu_(%input.29), scope: __module.layer1/__module.layer1.1/__module.layer1.1.relu # /home/melon/miniconda3/envs/torch240/lib/python3.12/site-packages/torch/nn/functional.py:1498:0\n",
      "  return (%input.31)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 展开计算图\n",
    "torch._C._jit_pass_inline(jit_layer1.graph)\n",
    "print(jit_layer1.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 序列化\n",
    "jit_model.save(\"resnet18.pth\")\n",
    "jie_model = torch.jit.load(\"resnet18.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
