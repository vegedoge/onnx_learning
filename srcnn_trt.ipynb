{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torch.onnx\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super().__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.img_upsampler = nn.Upsample(\n",
    "            scale_factor = self.upscale_factor,\n",
    "            mode = 'bicubic',\n",
    "            align_corners = False\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.img_upsampler(x)\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.conv3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download checkpoint and test image\n",
    "urls = ['https://download.openmmlab.com/mmediting/restorers/srcnn/srcnn_x4k915_1x16_1000k_div2k_20200608-4186f232.pth', \n",
    "    'https://raw.githubusercontent.com/open-mmlab/mmediting/master/tests/data/face/000001.png'] \n",
    "names = ['srcnn.pth', 'face.png'] \n",
    "for url, name in zip(urls, names): \n",
    "    if not os.path.exists(name): \n",
    "        open(name, 'wb').write(requests.get(url).content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206863/2922022087.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('srcnn.pth')['state_dict']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_torch_model():\n",
    "    torch_model = SuperResolutionNet(upscale_factor=3)\n",
    "\n",
    "    state_dict = torch.load('srcnn.pth')['state_dict']\n",
    "\n",
    "    # Adapt the checkpoint\n",
    "    for old_key in list(state_dict.keys()):\n",
    "        new_key = '.'.join(old_key.split('.')[1:]) \n",
    "        state_dict[new_key] = state_dict.pop(old_key)\n",
    "        \n",
    "    torch_model.load_state_dict(state_dict)\n",
    "    torch_model.eval()\n",
    "    return torch_model\n",
    "        \n",
    "model = init_torch_model()\n",
    "input_img = cv2.imread('face.png').astype(np.float32)\n",
    "\n",
    "# HWC to NCHW\n",
    "input_img = np.transpose(input_img, (2, 0, 1))\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "\n",
    "# inference\n",
    "torch_output = model(torch.tensor(input_img)).detach().numpy()\n",
    "\n",
    "# NCHW to HWC\n",
    "torch_output = np.squeeze(torch_output, 0)\n",
    "torch_output = np.clip(torch_output, 0, 255)\n",
    "torch_output = np.transpose(torch_output, (1, 2, 0)).astype(np.uint8)\n",
    "\n",
    "# show\n",
    "cv2.imwrite('face_torch.png', torch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 256, 256)\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,#### 直接用Onnxruntime推理\n",
    "        \"srcnn.onnx\",\n",
    "        opset_version=11,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 直接用Onnxruntime推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# 获取推理器\n",
    "ort_session = ort.InferenceSession(\"srcnn.onnx\")\n",
    "ort_inputs = {'input': input_img}\n",
    "\n",
    "# 第一个参数是输出张量列表， 第二个为输入张量字典\n",
    "# 对应导出时候的输入输出名称\n",
    "ort_output = ort_session.run(['output'], ort_inputs)[0]\n",
    "\n",
    "ort_output = np.squeeze(ort_output, 0)\n",
    "ort_output = np.clip(ort_output, 0, 255)\n",
    "ort_output = ort_output.transpose(1, 2, 0).astype(np.uint8)\n",
    "cv2.imwrite('face_ort.png', ort_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
